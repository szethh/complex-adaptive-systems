{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Topic of assignment\n",
    "\n",
    "    Name: First, Last\n",
    "    Student #: s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Controlled Lotka-Volterra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1\n",
    "Create a stochastic Lotka-Volterra system that is solved using the Euler-Maruyama method. For the parameters, you can use: \n",
    "$ \\alpha = 1.1, \\beta = 0.4, \\delta = 0.1, \\gamma =0.4$ with an initial condition of $\\mathbf{x}_0 = (10,10)^\\top$. For the Brownian motion, you can use $\\sigma = 0.05$, multiplied with the state (this is called multiplicative noise). Make sure that your step size is small enough, and the duration of the system is sufficiently long for showing the long term evolution of the system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "Create a control function $u(x)$ that receives the current state as input and returns an action as output. This control function has to be defined in such a way that the system becomes stabilized at the fixed point $\\mathbf{x}^*_{\\text{equilibrium}} = (\\gamma / \\delta , \\alpha / \\beta )^\\top$. You are allowed to use this goal state in your definition of the control function.\n",
    "\n",
    "For the result, show both the system evolution and control input over time, as well as the phase plane trajectory in a second figure. \n",
    "\n",
    "Then, explain:\n",
    "\n",
    "    - your reasoning behind the design of the control function;\n",
    "    \n",
    "    - discuss to what extent the system can be controlled to its equilibrium point;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = jnp.array([gamma/delta, alpha/beta]) \n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Linear Quadratic Regulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1 \n",
    "\n",
    "Simulate the completely observed discrete-time stochastic double integrator without control. Use $\\sigma_x^2$=0.01."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2 \n",
    "\n",
    "Compute the Linear Quadratic Regulator for the completely observed discrete-time stochastic double integrator. You may use 'scipy.linalg.solve_discrete_are' to compute the S matrix. You can assume that q = r = 0.5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control theory utilities\n",
    "from scipy.linalg import solve_discrete_are\n",
    "\n",
    "class LQR:\n",
    "    \"\"\"       \n",
    "    Discrete time linear quadratic regulator\n",
    "\n",
    "    state equation:\n",
    "    x_n+1 = x_n' A x_n + B u_n + e_n with e_n ~ N(0, W)\n",
    "\n",
    "    cost function\n",
    "    J = sum_n [x_n' Q x_n + u_n' R u_n]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A: jnp.array, B: jnp.array, W: jnp.array, \n",
    "                 Q: jnp.array, R: jnp.array) -> None:\n",
    "        \n",
    "        self.n_state = A.shape[0]\n",
    "        self.n_control = B.shape[1]\n",
    "\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.W = W\n",
    "\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "\n",
    "        # YOUR ANSWER HERE\n",
    "\n",
    "    def control(self, x):\n",
    "        return None # YOUR ANSWER HERE\n",
    "\n",
    "    def reward(self, x, u):\n",
    "        return None # YOUR ANSWER HERE\n",
    "    \n",
    "lqr = LQR(A, B, W, Q, R)\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3\n",
    "\n",
    "Compare the reward over time of the LQR controller with no control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Value iteration\n",
    "\n",
    "Use value iteration to find the optimal control sequence starting in state $s_1$ for the four-state toy problem as discussed in class. Use c1 = 4, c2 = 1, c3 = 1, c4 = 4, c5 = 2, c6 = 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
