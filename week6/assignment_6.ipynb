{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\setcounter{secnumdepth}{0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6 - Control Theory and System Identification\n",
    "\n",
    "    Name: First, Last\n",
    "    Student #: s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "from typing import Callable\n",
    "from jax.random import PRNGKey\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Linear Quadratic Gaussian control\n",
    "\n",
    "Last week we implemented the LQR. However, under partial observability or noisy measurements, the LQR can be made more robust by estimating the current state (also known as filtering). In the exercise, we will implement the LQG, which extends the LQR with optimal filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1\n",
    "\n",
    "Extend the discrete-time stochastic double integrator from last week to have noisy observations and that only the position is observed. You can either show the true state and observations in separate plots, or plot the observations over the true state in the same plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "T = 10\n",
    "ts = jnp.arange(0, T, dt)\n",
    "\n",
    "var_x = 0.01\n",
    "var_y = 0.1\n",
    "var0 = 0.1\n",
    "q = r = 0.5\n",
    "\n",
    "A = jnp.array([[1, dt], [0, 1]])\n",
    "B = jnp.array([[0], [dt]])\n",
    "W = dt*var_x*jnp.eye(2)\n",
    "\n",
    "C = None\n",
    "V = None\n",
    "\n",
    "mu0 = jnp.array([1.0,0.0])\n",
    "Sigma0 = var0 * jnp.eye(2)\n",
    "\n",
    "key = jr.PRNGKey(0)\n",
    "key, subkey = jr.split(key)\n",
    "\n",
    "x_init = None\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "y_init = None\n",
    "\n",
    "def simulate_step(carry, t):\n",
    "    x, key = carry\n",
    "    key, subkey1, subkey2 = jr.split(key, 3)\n",
    "    noise = None\n",
    "    next_x = None\n",
    "    y = None\n",
    "    return (next_x, key), (next_x, y)\n",
    "\n",
    "init_carry = (x_init, key)\n",
    "(_, _), (no_control_xs, no_control_ys) = jax.lax.scan(simulate_step, init_carry, ts[:-1])\n",
    "\n",
    "# Prepend initial state\n",
    "no_control_xs = jnp.vstack([x_init, no_control_xs])\n",
    "no_control_ys = jnp.vstack([y_init, no_control_ys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2\n",
    "\n",
    "Compute the optimal control solution with the LQG for the partially observed discrete-time stochastic double integrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control theory utilities\n",
    "from scipy.linalg import solve_discrete_are\n",
    "\n",
    "class LQG:\n",
    "    \"\"\"       \n",
    "    Discrete time linear quadratic regulator\n",
    "\n",
    "    state equation:\n",
    "    x_n+1 = x_n' A x_n + B u_n + e_n with e_n ~ N(0, W)\n",
    "\n",
    "    initial state x(0) ~ N(mu0, Sigma0)\n",
    "\n",
    "    cost function\n",
    "    J = sum_n [x_n' Q x_n + u_n' R u_n]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A: jnp.array, B: jnp.array, W: jnp.array, \n",
    "                 Q: jnp.array, R: jnp.array, C: jnp.array, V: jnp.array) -> None:\n",
    "        \n",
    "        self.n_state = A.shape[0]\n",
    "        self.n_control = B.shape[1]\n",
    "\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.W = W\n",
    "\n",
    "        self.C = C\n",
    "        self.V = V\n",
    "\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "\n",
    "        # solution to the DARE\n",
    "        self.S = None\n",
    "\n",
    "        # Feedback gain matrix\n",
    "        self.L = None\n",
    "\n",
    "    def control(self, x):\n",
    "        return\n",
    "\n",
    "    def reward(self, x, u):\n",
    "        return\n",
    "    \n",
    "    def kalman_filter(self, mu, Sigma, y, uk=0.0):\n",
    "        \"\"\"\n",
    "        Kalman Filter function for state estimation\n",
    "        \n",
    "        Input\n",
    "        mu: np.array        current mean state estimate\n",
    "        Sigma: np.array     current uncertainty estimate\n",
    "        y: np.array         last observation\n",
    "        uk: np.array        last control signal\n",
    "        \n",
    "        Return\n",
    "        muk: np.array       updated mean state estimate\n",
    "        Sigmak: np.array    updated uncerstainty estimate\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # KF prediction step\n",
    "\n",
    "        muk1 = None\n",
    "\n",
    "        Sigmak1 = None\n",
    "\n",
    "        # KF update step\n",
    "        r = None # innovation\n",
    "        K = None # optimal Kalman gain\n",
    "        \n",
    "        muk = None\n",
    "        Sigmak = None\n",
    "        \n",
    "        return muk, Sigmak\n",
    "    \n",
    "Q = None\n",
    "R = None\n",
    "\n",
    "lqg = LQG(A, B, W, Q, R, C, V)\n",
    "\n",
    "key = jr.PRNGKey(0)\n",
    "key, subkey = jr.split(key)\n",
    "x_init = None\n",
    "\n",
    "subkey, key = jax.random.split(subkey)\n",
    "y_init = None\n",
    "u_init = None\n",
    "\n",
    "def simulate_step(carry, t):\n",
    "    x, mu, Sigma, key = carry\n",
    "    key, subkey1, subkey2 = jax.random.split(key, 3)\n",
    "\n",
    "    u = None\n",
    "\n",
    "    next_x = None\n",
    "    y = None\n",
    "\n",
    "    next_mu, next_Sigma = None\n",
    "\n",
    "    return (next_x, next_mu, next_Sigma, key), (next_x, y, u, next_mu, next_Sigma)\n",
    "\n",
    "init_carry = (x_init, mu0, Sigma0, key)\n",
    "(_, _, _, _), (control_xs, control_ys, control_us, control_mus, control_Sigmas) = jax.lax.scan(simulate_step, init_carry, ts[:-1])\n",
    "\n",
    "# Prepend initial state\n",
    "control_xs = jnp.vstack([x_init, control_xs])\n",
    "control_ys = jnp.vstack([y_init, control_ys])\n",
    "control_us = jnp.vstack([u_init, control_us])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "\n",
    "Show the cummulative reward over time with different levels of observation noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Simulating Continuous time RNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate a continuous-time Recurrent Neural Network (CTRNN) to analyze its behaviour over time. \n",
    "\n",
    "\\begin{equation} f_{\\text{CTRNN}}(x) = \\frac{1}{\\tau} \\cdot \\left( -x + W \\sigma(\\mathbf{x}) + b \\right), \\end{equation}\n",
    "\n",
    "where: \n",
    "\\begin{align*}\n",
    "    W &= \\begin{pmatrix} 4.5 & 1.0 \\\\ -1.0 & 4.5 \\end{pmatrix}\\\\\n",
    "    b &= \\begin{pmatrix} -2.75 & -1.75  \\end{pmatrix} \\\\\n",
    "    \\tau &= 1.0\n",
    "\\end{align*}\n",
    "\n",
    "Use jax.vmap to compute the vectors in the phase plane. Plot several trajectories of the CTRNN with different initial conditions in the phase plane."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "w = None\n",
    "b = None\n",
    "tau = None\n",
    "\n",
    "dt = 0.1\n",
    "T = 10000\n",
    "ts = jnp.arange(0, T) * dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return\n",
    "\n",
    "def CTRNN(x, args):\n",
    "    w, b = args\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = jnp.arange(0, 100, dt)\n",
    "solver = None\n",
    "\"\"\"Simulate trajectories \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" visualize trajectories and phase plane\"\"\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: System identification with neural networks\n",
    "\n",
    "Besides simulating a neural network with a given set of weights, one can learn the weights such that the integrated network over time resembles observed data as closely as possible. In the next part, we will create a neural network that learns a dynamical system from a given a set of observed noisy measurements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "i) Create a function 'initialize_mlp()' initializes a set of network parameters according to the documentation. \n",
    "\n",
    "ii) Then, create a function 'network()' that takes a state x and a set of parameters as input, and returns the output of the neural network according to the documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER:\n",
    "def initialize_mlp(layer_sizes, key:PRNGKey, scale:float=1e-2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        layer_sizes (tuple) Tuple of shapes of the neural network layers. \n",
    "                            Includes the input shape, hidden layer shape, and output layer shape: (input_dim, hidden_dim, ..., output_dim.)\n",
    "        key (PRNGKey) \n",
    "        scale (float) standard deviation of initial weights and biases\n",
    "\n",
    "    Return: \n",
    "        params (List) Tuple of weights and biases - [ (weights_1, biases_1), ..., (weights_n, biases_n) ]\n",
    "    \"\"\"\n",
    "    keys = jr.split(key, 2*len(layer_sizes))\n",
    "    params = []\n",
    "\n",
    "    return \n",
    "\n",
    "def network(x, params):\n",
    "    \"\"\" Standard MLP.\n",
    "    \n",
    "    Inputs:\n",
    "        params (PyTree) Parameters of the policy network, represented as PyTree. \n",
    "        x (D,) input state, where D is the dimensionality of the state observation.\n",
    "        \"\"\"\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "iii) Initialize a 2 layer network with input and output dimensions of 2, and two hidden layers of 32 hidden unit, using your newly created function 'initialize_mlp()'. \n",
    "\n",
    "iv) Initiate an Euler or RK4 step function from the previous exercise, but now instead give your 'network()' as the differential function 'f'.\n",
    "\n",
    "v) Come up with a reasonable learning rate to train your model with, and a reasonable number of gradient descent steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jr.split(jr.PRNGKey(0))\n",
    "\n",
    "ts = jnp.load('ts.npy') # download this from Brightspace\n",
    "ys = jnp.load('ys.npy') # download this from Brightspace\n",
    "data = (ts, ys)\n",
    "\n",
    "layer_sizes = None\n",
    "solver = None\n",
    "params = None\n",
    "key, subkey = jr.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "# set training parameters\n",
    "num_iters = None\n",
    "lr = None\n",
    "\n",
    "# Optimization\n",
    "optim = optax.adam(learning_rate=lr)\n",
    "state = optim.init(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3\n",
    "Define a loss function for your optimization problem, that:\n",
    "\n",
    "- uses the first observation as an initial condition for the system,\n",
    "- solves the system using your numerical integration method and the scan function from the first exercise,\n",
    "- returns the mean squared error loss between the predicted trajectories, and the target observations.\n",
    "\n",
    "You can use the given code below to run gradient descent with the Adam optimizer based on this loss function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, data):\n",
    "    ts, ys = data\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation. When running this multiple times, be sure to re-initialize your parameters. \n",
    "loss_vals = jnp.zeros((num_iters))\n",
    "loss = jax.jit(loss)\n",
    "for i in tqdm(range(num_iters)):\n",
    "    loss_val, loss_gradient = jax.value_and_grad(loss)(params, data)\n",
    "    updates, state = optim.update(loss_gradient, state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    loss_vals = loss_vals.at[i].set(loss_val)\n",
    "\n",
    "plt.plot(jnp.arange(num_iters), loss_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4\n",
    "Visualize your trained neural network predictions, and compare it with the observed data. In addition, create a slightly longer time horizon of 70 time units and comment on the forecast of the network: is it in line with what we can reasonably expect of the unknown system?\n",
    "\n",
    "If the network predictions do not resemble the observations, consider changing the learning rate or number of training iterations during training, or inspecting the correctness of your loss function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
